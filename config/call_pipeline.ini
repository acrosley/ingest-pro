[Paths]
TranscriptInputDirectory = .
StaffMapFile = .\config\staff_map.txt
DatabaseDirectory = .\output\Database
JsonOutputDirectory = .\output\ALL_JSON_FILES
CentralTranscriptOutputDirectory = .\output\ALL_TRANSCRIPT_FILES

[FileMonitoring]
CheckIntervalSeconds = 3
CompletionThresholdSeconds = 10
AllowedExtensions = .wav,.mp3,.m4a

[Transcription]
MaxTranscriptionWorkers = 4
ProcessNewAudioOnStart = true
# Transcription Engine: "google_cloud_stt", "gemini", or "assemblyai"
# google_cloud_stt: Word-level confidence, but complex setup and file length limits
# gemini: Excellent accuracy, simple, but no confidence scores
# assemblyai: Best of both - excellent accuracy + word-level confidence (RECOMMENDED)
TranscriptionEngine = assemblyai

# Gemini settings (used if TranscriptionEngine = gemini)
GeminiModelName = gemini-2.0-flash
GeminiApiTimeoutSeconds = 1200

# Google Cloud STT settings (used if TranscriptionEngine = google_cloud_stt)
# See: https://cloud.google.com/speech-to-text/docs/apis
GoogleCloudSTT_LanguageCode = en-US

# Model options: phone_call (best for calls), latest_long, latest_short
# phone_call is specifically optimized for telephone audio quality
GoogleCloudSTT_Model = phone_call

# Use enhanced models for maximum accuracy (costs more but much better)
GoogleCloudSTT_UseEnhanced = true

# Audio encoding - IMPORTANT: Set this to match your audio format
# Options: LINEAR16, MULAW, ALAW, FLAC, OGG_OPUS, MP3
# Your files are MULAW (mu-law) encoded - typical for telephone recordings
GoogleCloudSTT_Encoding = MULAW

# Sample rate in Hz - IMPORTANT: Must match your audio files
# Common values: 8000 (telephone), 16000 (HD voice), 44100 (CD quality)
# Your files are 8000 Hz (standard telephone quality)
GoogleCloudSTT_SampleRateHertz = 8000

GoogleCloudSTT_EnableWordConfidence = true
GoogleCloudSTT_EnableWordTimeOffsets = true
GoogleCloudSTT_EnableAutomaticPunctuation = true
GoogleCloudSTT_EnableSpeakerDiarization = true
GoogleCloudSTT_DiarizationSpeakerCount = 2

# Include timestamps in transcript output (format: [MM:SS] Speaker: text)
GoogleCloudSTT_IncludeTimestamps = true

# Enable speech adaptation for domain-specific terms
GoogleCloudSTT_EnableSpeechAdaptation = true

# Number of alternative transcriptions to consider
GoogleCloudSTT_MaxAlternatives = 3

# Profanity filter (set to false for legal/compliance accuracy)
GoogleCloudSTT_ProfanityFilter = false

# AssemblyAI settings (used if TranscriptionEngine = assemblyai)
# Docs: https://www.assemblyai.com/docs/speech-to-text/overview

# Authentication
AssemblyAI_ApiKey = 46911ef4cbba48a0a0f4b18c9ba43d1e

# Speech Model Selection
# Options: universal, slam_1
# universal: Fastest, most robust, broadest language support (recommended, uses word_boost)
# slam_1: Most customizable for transcription (English only, beta, uses keyterms_prompt) ($0.27/hour)
AssemblyAI_SpeechModel = slam_1

# Basic transcription settings
AssemblyAI_EnableSpeakerLabels = true
# Note: LanguageCode setting is sent to API but slam_1 model is English-only
AssemblyAI_LanguageCode = en_us
AssemblyAI_IncludeTimestamps = true

# Audio format (set to true if recording separate channels for each speaker)
AssemblyAI_DualChannel = false

# Formatting options
AssemblyAI_Punctuate = true
AssemblyAI_FormatText = true
AssemblyAI_DisfluenciesFilter = false

# Word boosting - boost accuracy for specific words (uses nouns_to_expect.txt)
AssemblyAI_EnableWordBoost = true
AssemblyAI_WordBoostParam = default

# PII (Personally Identifiable Information) Redaction
# IMPORTANT for legal/HIPAA compliance!
# Options: redact or substitute
AssemblyAI_RedactPii = false
AssemblyAI_RedactPiiAudio = false
AssemblyAI_RedactPiiPolicies = medical_process,medical_condition,injury,blood_type,drug,date_of_birth,drivers_license,email_address,location,money_amount,person_name,phone_number,credit_card_number,credit_card_cvv,credit_card_expiration,ssn

# Content Safety/Moderation (flags sensitive content)
AssemblyAI_ContentSafety = false

# Entity Detection (identifies names, organizations, locations, etc.)
AssemblyAI_EntityDetection = false

# Sentiment Analysis (per sentence sentiment)
AssemblyAI_SentimentAnalysis = false

# Auto Highlights (key phrases and important moments)
AssemblyAI_AutoHighlights = false

# Summarization (AI-generated summary of conversation)
AssemblyAI_Summarization = false
AssemblyAI_SummaryModel = informative
AssemblyAI_SummaryType = bullets

[Analysis]
QueueSize = 50
MaxWorkers = 2
MinTranscriptSize = 100
CheckIntervalSeconds = 5
ProcessExistingOnStart = false
OutputFormat = both

# Enable transcript normalization during processing
EnableTranscriptNormalization = true

# Enable JSON file normalization for newly created files
EnableJsonNormalization = true

# Normalize all existing JSON files on startup (use with caution)
# Set to true to fix existing parsing errors, false for normal operation
NormalizeExistingJsonOnStart = false

[Gemini]
ModelName = gemini-2.0-flash
ApiTimeoutSeconds = 1200
KeyringServiceName = MyGeminiApp
KeyringUsername = gemini_api_key_user

[Logging]
LogDirectory = .\output\Logs
LogFilename = call_pipeline.log
LogLevel = INFO
LogMaxBytes = 10485760
LogBackupCount = 5

[Review]
Enabled = true
AlignmentModel = base
AlignmentDevice = cpu
OutputDirectory = .\output\Review
LowConfidenceThreshold = 0.70
AlignmentMatchThreshold = 0.6
AlignmentSearchWindow = 8
FlagNumbers = true
FlagUnknownLexicon = false
MinLexiconWordLength = 4
ReuseAlignmentModel = true

# Use Google Cloud STT confidence data if available (faster and more accurate)
# Set to false to always use Whisper for alignment
PreferGoogleCloudConfidence = true
