# ğŸ“ IngestPro - Call Recording Transcription & Review System

Professional call recording transcription pipeline with AI-powered accuracy verification and manual review tools. Built for law firms and organizations requiring high-accuracy transcription with human oversight.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸ¯ Overview

IngestPro is an end-to-end call transcription system that combines multiple AI transcription engines with intelligent review workflows to ensure maximum accuracy. Perfect for legal, medical, and business environments where transcription quality is critical.

### **Key Features**

âœ… **Multiple Transcription Engines**
- AssemblyAI (primary) with advanced speech models
- Google Cloud Speech-to-Text
- Google Gemini AI
- Configurable fallback system

âœ… **Smart Review System**
- Real-time confidence scoring
- Pattern-based flagging (names, numbers, dates, phone numbers)
- Interactive web-based review UI
- Bulk correction and approval actions

âœ… **Automatic Quality Tracking**
- Tracks all manual corrections and approvals
- Generates actionable recommendations
- Identifies systematic issues
- Progressively improves accuracy over time

âœ… **Production Ready**
- Batch processing support
- Comprehensive error handling
- Detailed logging
- Configurable thresholds and settings

---

## ğŸ“‹ Requirements

- Python 3.8 or higher
- One or more transcription service API keys:
  - **AssemblyAI** (recommended) - [Get API Key](https://www.assemblyai.com/)
  - Google Cloud Speech-to-Text (optional)
  - Google Gemini (optional)

---

## ğŸš€ Quick Start

### 1. **Clone Repository**

```bash
git clone https://github.com/yourusername/ingest_pro.git
cd ingest_pro
```

### 2. **Install Dependencies**

```bash
pip install -r requirements.txt
```

### 3. **Configure API Keys**

Edit `config/call_pipeline.ini`:

```ini
[Transcription]
TranscriptionEngine = assemblyai
AssemblyAI_ApiKey = your_api_key_here
```

### 4. **Add Expected Terms (Optional but Recommended)**

Edit `config/nouns_to_expect.txt` with domain-specific terms:

```
Company Name
Common Names
Location Names
Technical Terms
```

### 5. **Process Your First Call**

```bash
python processor.py path/to/audio.wav
```

Outputs will be in the `output/` directory:
- `.txt` - Full transcript
- `.confidence.json` - Word-level confidence data
- `.review.json` - Flagged words for manual review

---

## ğŸ“ Usage

### **Basic Transcription**

```bash
# Single file
python processor.py audio/call001.wav

# Batch processing
python processor.py audio/*.wav
```

### **Manual Review Workflow**

1. **Start the review UI:**
   ```bash
   tools\review_tools\launch_assemblyai_review.bat
   ```

2. **Open browser:** `http://localhost:8000`

3. **Load review file:** Browse to `.review.json` or `.confidence.json`

4. **Review flagged words:**
   - âœ“ **Approve** correct words
   - âœï¸ **Correct** errors
   - ğŸ“– **Add to dictionary** for future processing

5. **Export:**
   - ğŸ’¾ Export corrections
   - ğŸ“„ Export corrected transcript
   - ğŸ’¿ Save review file

### **Automated Corrections Tracking**

Track all review actions for continuous improvement:

1. **Start API server:**
   ```bash
   tools\corrections\start_api.bat
   ```

2. **Review transcripts** (actions auto-log to database)

3. **Analyze patterns:**
   ```bash
   tools\corrections\analyze.bat
   ```

4. **View recommendations:**
   ```bash
   tools\corrections\view_approvals.bat
   ```

---

## ğŸ“ Project Structure

```
ingest_pro/
â”œâ”€â”€ processor.py                    # Main transcription pipeline
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ call_pipeline.ini          # Main configuration file
â”‚   â””â”€â”€ nouns_to_expect.txt        # Domain-specific vocabulary
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ transcription_engine.py    # Transcription engine implementations
â”‚   â”œâ”€â”€ review_tools/              # Manual review system
â”‚   â”‚   â”œâ”€â”€ assemblyai_review_generator.py
â”‚   â”‚   â”œâ”€â”€ assemblyai_review_ui.html
â”‚   â”‚   â””â”€â”€ launch_assemblyai_review.bat
â”‚   â””â”€â”€ corrections/               # Corrections tracking system
â”‚       â”œâ”€â”€ corrections_database.py
â”‚       â”œâ”€â”€ analyze_corrections.py
â”‚       â”œâ”€â”€ view_approvals.py
â”‚       â””â”€â”€ corrections_api.py
â”œâ”€â”€ output/                        # Generated transcripts
â””â”€â”€ docs/                          # Additional documentation
```

---

## âš™ï¸ Configuration

### **Transcription Settings**

Edit `config/call_pipeline.ini`:

```ini
[Transcription]
# Engine selection
TranscriptionEngine = assemblyai

# AssemblyAI Settings
AssemblyAI_ApiKey = your_key_here
AssemblyAI_SpeechModel = universal          # or slam_1
AssemblyAI_EnableSpeakerLabels = true
AssemblyAI_LanguageCode = en_us

# Review System
ReviewEnabled = true
LowConfidenceThreshold = 0.60
CriticalConfidenceThreshold = 0.50
```

### **Review Configuration**

Fine-tune flagging thresholds in:

**JavaScript UI:** `tools/review_tools/assemblyai_review_ui.html` (lines 545-605)
```javascript
const REVIEW_CONFIG = {
    confidence: {
        critical: 0.50,      // Red flags
        low: 0.60,           // Yellow flags
        commonWords: 0.25,   // Very lenient for common words
    },
    // ... more settings
};
```

**Python Generator:** `tools/review_tools/assemblyai_review_generator.py` (lines 33-36)
```python
low_confidence_threshold: float = 0.60
critical_confidence_threshold: float = 0.50
common_words_confidence_threshold: float = 0.25
```

---

## ğŸ¯ Key Features Explained

### **1. Intelligent Flagging System**

Automatically flags words requiring review:

| Flag Type | Description | Priority |
|-----------|-------------|----------|
| **Critical Confidence** | Very low confidence (< 50%) | ğŸ”´ High |
| **Phone Numbers** | Detected phone numbers | ğŸ”´ High |
| **Money Amounts** | Dollar amounts | ğŸ”´ High |
| **Case Numbers** | 6+ digit numbers | ğŸ”´ High |
| **Names** | Capitalized words (potential names) | ğŸŸ¡ Medium |
| **Low Confidence** | Below threshold (< 60%) | ğŸŸ¡ Medium |
| **Dates & Times** | Date/time patterns | ğŸŸ¡ Medium |

### **2. Smart Word Classification**

The system intelligently categorizes words:

- **Common Words** (lower threshold): "the", "and", "a", "is", "to", "of"
- **Action Words**: "get", "want", "please", "request"
- **Medical/Business Terms**: "medical", "department", "patient", "office"
- **Expected Terms** (from dictionary): Never flagged for confidence

### **3. Real-Time Statistics**

The review UI shows live updates as you work:

- Total words in transcript
- Remaining flagged words (decreases as you approve)
- Flag percentage
- Average confidence
- High priority items remaining
- Corrections made
- Words approved
- Dictionary queue

### **4. Bulk Actions**

After approving or correcting a word, automatically:
- Detects other instances of the same word
- Prompts to apply action to all instances
- Logs each action individually for analysis

### **5. Corrections Analytics**

Track your review patterns over time:

```bash
# View what words are approved most often
tools\corrections\view_approvals.bat

# Generate comprehensive analysis report
tools\corrections\analyze.bat

# Get recommendations for:
# - Terms to add to dictionary
# - Threshold adjustments needed
# - Systematic patterns to fix
```

---

## ğŸ“Š Workflow Example

### **Typical Daily Workflow:**

1. **Morning: Process overnight calls**
   ```bash
   python processor.py audio/overnight/*.wav
   ```

2. **Review flagged transcripts**
   - Start review UI and API server
   - Load and review each `.review.json` file
   - Export corrected transcripts

3. **Weekly: Analyze patterns**
   ```bash
   tools\corrections\analyze.bat
   ```
   - Review recommendations
   - Add common terms to dictionary
   - Adjust thresholds if needed

4. **Monthly: Measure improvement**
   - Track approvals per call over time
   - Should decrease as system learns
   - Target: < 5 approvals per minute of audio

---

## ğŸ› ï¸ Advanced Features

### **Custom Transcription Engine**

Add your own engine by extending `TranscriptionEngine` class in `tools/transcription_engine.py`:

```python
class CustomSTT(TranscriptionEngine):
    def transcribe_file(self, audio_path: Path, **kwargs) -> TranscriptionResult:
        # Your implementation
        pass
```

### **Batch Processing with Logging**

```bash
# Process with detailed logs
python processor.py audio/*.wav > processing.log 2>&1
```

### **Custom Flagging Rules**

Modify flagging logic in `tools/review_tools/assemblyai_review_generator.py`:

```python
def _flag_word(word_data, word_index, all_words, config, expected_terms):
    # Add custom flagging logic
    if word_matches_custom_pattern(word):
        flags.append(WordFlag(...))
```

---

## ğŸ“š Documentation

- **[AssemblyAI Configuration](docs/ASSEMBLYAI_CONFIG_COMPLETE.md)** - Complete AssemblyAI setup guide
- **[Google Cloud STT Setup](docs/GOOGLE_CLOUD_STT_SETUP.md)** - Google Cloud configuration
- **[Expected Terms Guide](docs/EXPECTED_NOUNS_GUIDE.md)** - Building your dictionary
- **[Review System Guide](tools/review_tools/ASSEMBLYAI_REVIEW_README.md)** - Manual review details
- **[Corrections System](tools/corrections/README.md)** - Tracking and analytics
- **[Improvements Applied](tools/corrections/IMPROVEMENTS_APPLIED.md)** - Recent optimizations

---

## ğŸ”§ Troubleshooting

### **Common Issues:**

**"No module named 'assemblyai'"**
```bash
pip install -r requirements.txt
```

**"Invalid API key"**
- Check `config/call_pipeline.ini`
- Verify key at provider's dashboard
- Ensure no extra spaces in config

**"Too many words flagged"**
- Lower thresholds in config (see Configuration section)
- Add more terms to `config/nouns_to_expect.txt`
- Run `view_approvals.bat` to see what's being flagged

**"Review UI won't load"**
- Check if port 8000 is in use
- Try running as administrator
- Check firewall settings

---

## ğŸ“ˆ Performance Metrics

### **Typical Performance:**

| Metric | Initial | After Tuning |
|--------|---------|--------------|
| **Transcription Accuracy** | 95%+ | 98%+ |
| **False Positive Flags** | 30-40% | 5-10% |
| **Review Time** | 5-10 min/call | 1-2 min/call |
| **Approvals Needed** | 50-60/call | 5-15/call |

### **Cost Estimates (AssemblyAI):**

- **Universal Model**: ~$0.15/hour of audio
- **SLAM_1 Model**: ~$0.27/hour of audio
- Average 2-minute call: ~$0.009

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **AssemblyAI** - Primary transcription engine
- **Google Cloud** - Speech-to-Text and Gemini AI services
- **Contributors** - Thank you to all who have contributed!

---

## ğŸ“§ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/ingest_pro/issues)
- **Documentation**: See `docs/` directory
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/ingest_pro/discussions)

---

## ğŸ—ºï¸ Roadmap

- [ ] Real-time transcription support
- [ ] Multi-language support expansion
- [ ] Speaker identification improvements
- [ ] Custom vocabulary training
- [ ] REST API for integration
- [ ] Docker containerization
- [ ] Cloud deployment options

---

**Made with â¤ï¸ for accurate transcription**

*Last Updated: October 2, 2025*

